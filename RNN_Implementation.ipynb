{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yvfl_DbclIyT"
      },
      "source": [
        "# Implementing a Recurrent Neural Network for Sequential Data\n",
        "\n",
        "In this exercise we will develop a recurrent neural network with vanilla RNN and GRU to perform classification, and test it out on the Text Document Classification Dataset. ðŸ˜€"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I82oSCDhl543"
      },
      "source": [
        "## Loading Text Document Classification Dataset.\n",
        "\n",
        "Dataset contains different categories of text data. It contains labels for five different categories.\n",
        "Politics = 0, Sport = 1, Technology = 2, Entertainment = 3, Business = 4."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m95kJBSNnoUt",
        "outputId": "7f5366bc-01fe-480a-92a3-ebede578c25c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2225, 2)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# load dataset\n",
        "data = pd.read_csv(\"./df_file.csv\")\n",
        "print(data.shape)\n",
        "\n",
        "def preprocess_data(data, text_column, label_column):\n",
        "    texts = data[text_column].values\n",
        "    labels = data[label_column].values\n",
        "    return texts, labels\n",
        "\n",
        "texts, labels = preprocess_data(data, 'Text', 'Label')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sMIyNiD1W3iC",
        "outputId": "93a02c12-adb2-4ed9-b5db-9ad404a58df8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2225, 100)\n"
          ]
        }
      ],
      "source": [
        "# Build Tokenizer\n",
        "tokenizer = Tokenizer(num_words=5000)  #num_words : number of word dictionary\n",
        "tokenizer.fit_on_texts(texts)\n",
        "sequences = tokenizer.texts_to_sequences(texts)\n",
        "\n",
        "# padding for sentence length\n",
        "max_seq_length = 100\n",
        "padded_sequences = pad_sequences(sequences, maxlen=max_seq_length)\n",
        "\n",
        "print(padded_sequences.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gsWaEmAgYk8z",
        "outputId": "e23fc092-4b76-4b7c-fad3-1bfbfd6b6379"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input batch shape: torch.Size([32, 100])\n",
            "Target batch shape: torch.Size([32])\n"
          ]
        }
      ],
      "source": [
        "# split dataset\n",
        "train_features, test_features, train_labels, test_labels = train_test_split(padded_sequences, labels, test_size=0.3, random_state=42)\n",
        "valid_features, test_features, valid_labels, test_labels = train_test_split(test_features, test_labels, test_size=0.5, random_state=42)\n",
        "\n",
        "# change into tensor\n",
        "train_features = torch.tensor(train_features, dtype=torch.long)\n",
        "train_labels = torch.tensor(train_labels, dtype=torch.long)\n",
        "valid_features = torch.tensor(valid_features, dtype=torch.long)\n",
        "valid_labels = torch.tensor(valid_labels, dtype=torch.long)\n",
        "test_features = torch.tensor(test_features, dtype=torch.long)\n",
        "test_labels = torch.tensor(test_labels, dtype=torch.long)\n",
        "\n",
        "# Build DataLoader\n",
        "train_dataset = TensorDataset(train_features, train_labels)\n",
        "valid_dataset = TensorDataset(valid_features, valid_labels)\n",
        "test_dataset = TensorDataset(test_features, test_labels)\n",
        "\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=32, shuffle=True)\n",
        "valid_loader = DataLoader(dataset=valid_dataset, batch_size=32, shuffle=False)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# print batch size\n",
        "for batch in train_loader:\n",
        "    inputs, targets = batch\n",
        "    print(f\"Input batch shape: {inputs.shape}\")\n",
        "    print(f\"Target batch shape: {targets.shape}\")\n",
        "    break\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFn85HMEGsY0"
      },
      "source": [
        "Code for testing model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JXjB8Q8vtLg-"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, val_loader):\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            inputs = batch[0].to(device)\n",
        "            labels = batch[1].to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    avg_loss = val_loss / len(val_loader)\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f'Validation Loss: {avg_loss:.4f}, Accuracy: {accuracy:.2f}%')\n",
        "    return avg_loss\n",
        "\n",
        "def test_model(model, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            inputs = batch[0].to(device)\n",
        "            labels = batch[1].to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            test_loss += loss.item()\n",
        "\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    avg_loss = test_loss / len(test_loader)\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f'Test Loss: {avg_loss:.4f}, Accuracy: {accuracy:.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4tmviyweFVD1"
      },
      "source": [
        "## Vanilla RNN Implementation\n",
        "\n",
        "Here we will implement vanilla RNN model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "911_8XSIFUBZ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class VanillaRNN(nn.Module):\n",
        "    #####fill in the blanks#####\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_size, output_size):\n",
        "        super(VanillaRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embedding_dim)\n",
        "\n",
        "        # Weights for input to hidden connection\n",
        "        self.Wx = nn.Linear(##blank##, ##blank##)\n",
        "        # Weights for hidden to hidden connection\n",
        "        self.Wh = nn.Linear(##blank##, ##blank##)\n",
        "        # Fully connected layer to map hidden state to output\n",
        "        self.fc = nn.Linear(##blank##, ##blank##)\n",
        "\n",
        "        # Activation function (tanh) for the hidden state\n",
        "        self.tanh = nn.Tanh()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        batch_size, seq_len, _ = x.size()\n",
        "\n",
        "        # Initialize hidden state with zeros\n",
        "        h = torch.zeros(batch_size, self.hidden_size).to(x.device)\n",
        "\n",
        "        # Iterate over each time step\n",
        "        for t in range(seq_len):\n",
        "            xt = ##fill in your code##  # Select the t-th time step input\n",
        "            h = ##fill in your code##  # Update hidden state\n",
        "\n",
        "        # Use the hidden state from the last time step to predict the output\n",
        "        out = self.fc(h)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3G66ByEGF1Dl"
      },
      "outputs": [],
      "source": [
        "# model params\n",
        "vocab_size = 5000\n",
        "embedding_dim = 64\n",
        "hidden_size = 128\n",
        "output_size = 5\n",
        "\n",
        "# build GRU model\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = VanillaRNN(vocab_size, embedding_dim, hidden_size, output_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uYu1c-HEIjh0"
      },
      "source": [
        "Here we will train and test vanilla RNN model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u9JzMMZ5GmW_"
      },
      "outputs": [],
      "source": [
        "# hyperparameters\n",
        "learning_rate = 0.001\n",
        "num_epochs = 10\n",
        "\n",
        "# loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "#start training\n",
        "best_val_loss = float('inf')\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "\n",
        "    for batch in train_loader:\n",
        "        inputs = batch[0].to(device)\n",
        "        labels = batch[1].to(device)\n",
        "\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
        "    val_loss = evaluate_model(model, valid_loader)\n",
        "\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        torch.save(model.state_dict(), 'rnn_best_model.pth')\n",
        "        print(f\"Best model saved with validation loss: {val_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uXw_So68IrMw"
      },
      "source": [
        "Here you can get your final test accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2UmhMXcsG-Va"
      },
      "outputs": [],
      "source": [
        "print(\"Evaluating on test set:\")\n",
        "test_model(model, test_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GXSOwA3KuCGo"
      },
      "source": [
        "## GRU (Gated Recurrent Unit) Implementation\n",
        "\n",
        "Here, we will implement GRU model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oTNCyu7tlDnS"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class GRUCell(nn.Module):\n",
        "  #####fill in the blanks#####\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(GRUCell, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        # Update gate\n",
        "        self.W_z = nn.Linear(##blank##, ##blank##)\n",
        "        self.U_z = nn.Linear(##blank##, ##blank##)\n",
        "\n",
        "        # Reset gate\n",
        "        self.W_r = nn.Linear(##blank##, ##blank##)\n",
        "        self.U_r = nn.Linear(##blank##, ##blank##)\n",
        "\n",
        "        # Candidate hidden state\n",
        "        self.W_h = nn.Linear(##blank##, ##blank##)\n",
        "        self.U_h = nn.Linear(##blank##, ##blank##)\n",
        "\n",
        "    def forward(self, x, h_prev):\n",
        "        # Update gate\n",
        "        # hint : The update gate controls how much of the previous hidden state (h_prev)\n",
        "        # should be carried forward to the next hidden state.\n",
        "        z_t = ##fill in your code##\n",
        "\n",
        "        # Reset gate\n",
        "        # hint : The reset gate determines how much of the previous hidden state\n",
        "        # should be \"reset\" or ignored when computing the candidate hidden state\n",
        "        r_t =##fill in your code##\n",
        "\n",
        "        # Candidate hidden state\n",
        "        # hint : The candidate hidden state is computed using a combination of the reset hidden state and the current input.\n",
        "        h_tilde = ##fill in your code##\n",
        "\n",
        "        # New final hidden state\n",
        "        # The final hidden state is a blend of the previous hidden state and the candidate hidden state\n",
        "        h_t = ##fill in your code##\n",
        "\n",
        "        return h_t\n",
        "\n",
        "class GRUModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_size, output_size):\n",
        "        super(GRUModel, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embedding_dim)\n",
        "        self.gru_cell = GRUCell(embedding_dim, hidden_size)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        batch_size, seq_len, _ = x.size()\n",
        "        h_t = torch.zeros(batch_size, self.hidden_size).to(x.device)\n",
        "\n",
        "        for t in range(seq_len):\n",
        "            h_t = ##fill in your code##\n",
        "\n",
        "        out = self.fc(h_t)\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VciDOg7yueId"
      },
      "outputs": [],
      "source": [
        "# model params\n",
        "vocab_size = 5000\n",
        "embedding_dim = 64\n",
        "hidden_size = 128\n",
        "output_size = 5\n",
        "\n",
        "# build GRU model\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = GRUModel(vocab_size, embedding_dim, hidden_size, output_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMQbvnUd2MY0"
      },
      "source": [
        "Here we will train and test our GRU model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TrJWCBlFnEos"
      },
      "outputs": [],
      "source": [
        "# hyperparameters\n",
        "learning_rate = 0.001\n",
        "num_epochs = 20\n",
        "\n",
        "# loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "#start training\n",
        "best_val_loss = float('inf')\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "\n",
        "    for batch in train_loader:\n",
        "        inputs = batch[0].to(device)\n",
        "        labels = batch[1].to(device)\n",
        "\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
        "    val_loss = evaluate_model(model, valid_loader)\n",
        "\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        torch.save(model.state_dict(), 'gru_best_model.pth')\n",
        "        print(f\"Best model saved with validation loss: {val_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IPPPpCMd2b8C"
      },
      "source": [
        "Here you can get your final test accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TMmgVhbB2cUL"
      },
      "outputs": [],
      "source": [
        "print(\"Evaluating on test set:\")\n",
        "test_model(model, test_loader)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
